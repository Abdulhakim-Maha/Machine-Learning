{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet-5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-29 09:29:33.610757: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-29 09:29:33.771678: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-29 09:29:33.771712: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-29 09:29:34.643863: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-29 09:29:34.643944: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-29 09:29:34.643953: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets.mnist import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 18s 2us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((60000, 28, 28, 1))\n",
    "X_test = X_test.reshape((10000, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.pad(X_train, ((0,0), (2,2), (2,2), (0,0)), 'constant')\n",
    "X_test = np.pad(X_test, ((0,0), (2,2), (2,2), (0,0)), 'constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_shape = X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, AvgPool2D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters=6, kernel_size=(5,5), activation='relu', input_shape=in_shape))\n",
    "model.add(AvgPool2D((2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters=16, kernel_size=(5,5), activation='relu'))\n",
    "model.add(AvgPool2D((2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters=120, kernel_size=(5,5), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(84, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_9 (Conv2D)           (None, 28, 28, 6)         156       \n",
      "                                                                 \n",
      " average_pooling2d_2 (Averag  (None, 14, 14, 6)        0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 10, 10, 16)        2416      \n",
      "                                                                 \n",
      " average_pooling2d_3 (Averag  (None, 5, 5, 16)         0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 1, 1, 120)         48120     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 120)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 84)                10164     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                850       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 [==============================] - 8s 16ms/step - loss: 0.3774 - accuracy: 0.9189 - val_loss: 0.0796 - val_accuracy: 0.9731\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0730 - accuracy: 0.9776 - val_loss: 0.0656 - val_accuracy: 0.9805\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.0552 - accuracy: 0.9832 - val_loss: 0.0440 - val_accuracy: 0.9843\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.0439 - accuracy: 0.9859 - val_loss: 0.0368 - val_accuracy: 0.9890\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.0369 - accuracy: 0.9883 - val_loss: 0.0394 - val_accuracy: 0.9882\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.0320 - accuracy: 0.9901 - val_loss: 0.0447 - val_accuracy: 0.9860\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0284 - accuracy: 0.9909 - val_loss: 0.0341 - val_accuracy: 0.9888\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.0252 - accuracy: 0.9918 - val_loss: 0.0357 - val_accuracy: 0.9882\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.0229 - accuracy: 0.9927 - val_loss: 0.0430 - val_accuracy: 0.9872\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 6s 14ms/step - loss: 0.0215 - accuracy: 0.9928 - val_loss: 0.0504 - val_accuracy: 0.9848\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.0199 - accuracy: 0.9937 - val_loss: 0.0432 - val_accuracy: 0.9868\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.0192 - accuracy: 0.9938 - val_loss: 0.0436 - val_accuracy: 0.9867\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 6s 14ms/step - loss: 0.0178 - accuracy: 0.9940 - val_loss: 0.0415 - val_accuracy: 0.9881\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 6s 14ms/step - loss: 0.0157 - accuracy: 0.9947 - val_loss: 0.0547 - val_accuracy: 0.9867\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.0134 - accuracy: 0.9955 - val_loss: 0.0498 - val_accuracy: 0.9868\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.0124 - accuracy: 0.9959 - val_loss: 0.0408 - val_accuracy: 0.9894\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.0120 - accuracy: 0.9959 - val_loss: 0.0515 - val_accuracy: 0.9877\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.0158 - accuracy: 0.9947 - val_loss: 0.0413 - val_accuracy: 0.9887\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 6s 14ms/step - loss: 0.0125 - accuracy: 0.9960 - val_loss: 0.0482 - val_accuracy: 0.9874\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.0134 - accuracy: 0.9956 - val_loss: 0.0544 - val_accuracy: 0.9864\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=20, batch_size=128, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.image import rgb_to_grayscale\n",
    "from PIL import ImageOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img('digit8.png', target_size=(32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAA7ElEQVR4nO2UOw6DMAyG7apD2MiWNbfKEbgJV2CDWzBzI7aM7oCaUmhMzEMglX9ASuz4E34hEcGRehwa/QbcAACw1uJbTdOsIVBcxpixA+8cEzKDhvhlnRwTdXYNghBx+EorwQGIKFQ45LTrugGWqCdvJiKttXMu3NR1ned5lmXe+yQC3wNt2/70WXz48VwwRwIppcqy3AowxjjnpOyJBHMgsgadNweImNon6wAAoJSKmaqqSgRE87hLAeBCu2gsRCyKItVZmiKtdd/3ifkB5g+89/OlZq0VRQdm2Q3LYM4QRQcmRXvpkl30Z4AX1na8xGtMCJgAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = ImageOps.invert(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255.0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = rgb_to_grayscale(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.expand_dims(img, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 32, 32, 1)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 32, 32, 1)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 125ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09450544, 0.08934963, 0.09955046, 0.09851301, 0.09951252,\n",
       "        0.09819793, 0.08939937, 0.08237698, 0.1295337 , 0.11906093]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.095, 0.089, 0.1  , 0.099, 0.1  , 0.098, 0.089, 0.082, 0.13 ,\n",
       "        0.119]], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = np.argmax(y_pred, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(img[0], cmap=plt.cm.gray_r)\n",
    "plt.title('Predited: {}'.format(predicted[0]))\n",
    "plt.yticks([])\n",
    "plt.xticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]]], dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
